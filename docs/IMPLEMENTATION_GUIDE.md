# êµ¬í˜„ ê°€ì´ë“œë¼ì¸

## ê°œë°œ ìˆœì„œ ë° ì²´í¬ë¦¬ìŠ¤íŠ¸

---

## Phase 1: í™˜ê²½ ì„¤ì • (30ë¶„)

### 1-1. Python ê°€ìƒí™˜ê²½ ìƒì„±

```bash
# Windows
python -m venv venv
venv\Scripts\activate

# Mac/Linux
python -m venv venv
source venv/bin/activate
```

### 1-2. íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

**í•„ìˆ˜ íŒ¨í‚¤ì§€**:
- `langchain` - LLM í†µí•©
- `langgraph` - ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- `langchain-openai` - OpenAI ì—°ë™
- `chainlit` - UI
- `python-dotenv` - í™˜ê²½ ë³€ìˆ˜ ê´€ë¦¬

### 1-3. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# .env íŒŒì¼ ìƒì„±
cp .env.example .env
```

`.env` íŒŒì¼ì— ì¶”ê°€:
```
OPENAI_API_KEY=sk-your-key-here
MODEL_NAME=gpt-4
TEMPERATURE=0.0
```

### 1-4. í…ŒìŠ¤íŠ¸

```bash
python -c "import langchain; import langgraph; print('Success!')"
```

---

## Phase 2: ë¡œê·¸ íŒŒì„œ êµ¬í˜„ (1-2ì‹œê°„)

### ëª©í‘œ
ì›ì‹œ ë¡œê·¸ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ Python ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜

### íŒŒì¼: `src/utils/log_parser.py`

### êµ¬í˜„ ë‚´ìš©

#### 2-1. ë‹¨ì¼ ë¡œê·¸ ë¼ì¸ íŒŒì‹±

**ì…ë ¥**:
```
[2026-01-05 03:15:22] ERROR Database connection error: ECONNREFUSED
```

**ì¶œë ¥**:
```python
{
    "timestamp": "2026-01-05T03:15:22Z",
    "level": "ERROR",
    "message": "Database connection error: ECONNREFUSED",
    "raw": "[2026-01-05 03:15:22] ERROR Database connection error: ECONNREFUSED"
}
```

**íŒíŠ¸**:
```python
import re
from datetime import datetime

def parse_log_line(line: str) -> dict:
    """ë‹¨ì¼ ë¡œê·¸ ë¼ì¸ íŒŒì‹±"""
    # íŒ¨í„´: [YYYY-MM-DD HH:MM:SS] LEVEL Message
    pattern = r'\[(\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2})\] (\w+) (.+)'
    match = re.match(pattern, line)

    if match:
        timestamp, level, message = match.groups()
        return {
            "timestamp": timestamp.replace(' ', 'T') + 'Z',
            "level": level,
            "message": message.strip(),
            "raw": line
        }
    return None
```

#### 2-2. ì „ì²´ ë¡œê·¸ íŒŒì¼ íŒŒì‹±

**ì…ë ¥**: ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
**ì¶œë ¥**: íŒŒì‹±ëœ ë¡œê·¸ ë¦¬ìŠ¤íŠ¸ + í†µê³„

```python
def parse_log_file(file_path: str) -> dict:
    """ë¡œê·¸ íŒŒì¼ ì „ì²´ íŒŒì‹±"""
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    parsed_logs = []
    for line in lines:
        parsed = parse_log_line(line.strip())
        if parsed:
            parsed_logs.append(parsed)

    # í†µê³„ ê³„ì‚°
    stats = calculate_statistics(parsed_logs)

    return {
        "logs": parsed_logs,
        "statistics": stats
    }
```

#### 2-3. í†µê³„ ê³„ì‚°

```python
def calculate_statistics(logs: list) -> dict:
    """ë¡œê·¸ í†µê³„ ê³„ì‚°"""
    total = len(logs)

    # ë ˆë²¨ë³„ ì¹´ìš´íŠ¸
    level_counts = {}
    for log in logs:
        level = log['level']
        level_counts[level] = level_counts.get(level, 0) + 1

    # ì‹œê°„ ë²”ìœ„
    if logs:
        timestamps = [log['timestamp'] for log in logs]
        time_span = f"{timestamps[0]} ~ {timestamps[-1]}"
    else:
        time_span = "N/A"

    return {
        "total": total,
        "errors": level_counts.get('ERROR', 0),
        "warnings": level_counts.get('WARN', 0),
        "info": level_counts.get('INFO', 0),
        "debug": level_counts.get('DEBUG', 0),
        "time_span": time_span,
        "error_rate": level_counts.get('ERROR', 0) / total if total > 0 else 0
    }
```

### í…ŒìŠ¤íŠ¸

```python
# tests/test_log_parser.py
from src.utils.log_parser import parse_log_file

def test_parse_db_failure():
    result = parse_log_file('datasets/scenario-01-db-connection-failure/dataset-01.log')

    assert result['statistics']['total'] > 0
    assert result['statistics']['errors'] > 0
    print(f"âœ“ Parsed {result['statistics']['total']} logs")
    print(f"âœ“ Found {result['statistics']['errors']} errors")

if __name__ == '__main__':
    test_parse_db_failure()
```

---

## Phase 3: ë¶„ë¥˜ ì—ì´ì „íŠ¸ êµ¬í˜„ (2-3ì‹œê°„)

### ëª©í‘œ
ë¡œê·¸ë¥¼ ë¶„ì„í•´ì„œ ë¬¸ì œ ìœ í˜•(ì¸í”„ë¼/ë³´ì•ˆ/ì„±ëŠ¥/ì• í”Œë¦¬ì¼€ì´ì…˜)ê³¼ ì‹¬ê°ë„ íŒë‹¨

### íŒŒì¼: `src/agents/classifier.py`

### êµ¬í˜„ ë‚´ìš©

#### 3-1. í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì‘ì„±

```python
from langchain_core.prompts import ChatPromptTemplate

CLASSIFICATION_PROMPT = """ë‹¹ì‹ ì€ ë¡œê·¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ë¡œê·¸ í†µê³„ì™€ ìƒ˜í”Œì„ ë³´ê³  ë¬¸ì œ ìœ í˜•ê³¼ ì‹¬ê°ë„ë¥¼ íŒë‹¨í•˜ì„¸ìš”.

=== í†µê³„ ===
ì´ ë¡œê·¸ ìˆ˜: {total}
ì—ëŸ¬ ìˆ˜: {errors}
ê²½ê³  ìˆ˜: {warnings}
ì—ëŸ¬ ë¹„ìœ¨: {error_rate:.1%}

=== ìƒ˜í”Œ ë¡œê·¸ (ìµœê·¼ 10ê°œ) ===
{sample_logs}

=== ë¶„ì„ ìš”ì²­ ===
ë‹¤ìŒ í•­ëª©ì„ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
1. category: "infrastructure" | "security" | "performance" | "application"
2. severity: "critical" | "high" | "medium" | "low"
3. confidence: 0.0 ~ 1.0
4. reasoning: íŒë‹¨ ê·¼ê±° (í•œ ë¬¸ì¥)

ì˜ˆì‹œ:
{{
  "category": "infrastructure",
  "severity": "critical",
  "confidence": 0.95,
  "reasoning": "ì—°ì†ì ì¸ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ ê°ì§€"
}}
"""
```

#### 3-2. ë¶„ë¥˜ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤

```python
from langchain_openai import ChatOpenAI
import json

class ClassificationAgent:
    def __init__(self):
        self.llm = ChatOpenAI(
            model="gpt-4",
            temperature=0.0
        )
        self.prompt = ChatPromptTemplate.from_template(CLASSIFICATION_PROMPT)

    def classify(self, parsed_logs: list, statistics: dict) -> dict:
        """ë¡œê·¸ ë¶„ë¥˜"""
        # ìƒ˜í”Œ ë¡œê·¸ ì¶”ì¶œ (ìµœê·¼ 10ê°œ)
        sample_logs = "\n".join([
            f"{log['timestamp']} [{log['level']}] {log['message']}"
            for log in parsed_logs[-10:]
        ])

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        messages = self.prompt.format_messages(
            total=statistics['total'],
            errors=statistics['errors'],
            warnings=statistics['warnings'],
            error_rate=statistics['error_rate'],
            sample_logs=sample_logs
        )

        # LLM í˜¸ì¶œ
        response = self.llm.invoke(messages)

        # JSON íŒŒì‹±
        try:
            result = json.loads(response.content)
            return result
        except json.JSONDecodeError:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
            return {
                "category": "application",
                "severity": "medium",
                "confidence": 0.5,
                "reasoning": "ë¶„ë¥˜ ì‹¤íŒ¨"
            }
```

### í…ŒìŠ¤íŠ¸

```python
# tests/test_classifier.py
from src.utils.log_parser import parse_log_file
from src.agents.classifier import ClassificationAgent

def test_classify_db_failure():
    # ë¡œê·¸ íŒŒì‹±
    result = parse_log_file('datasets/scenario-01-db-connection-failure/dataset-01.log')

    # ë¶„ë¥˜
    classifier = ClassificationAgent()
    classification = classifier.classify(result['logs'], result['statistics'])

    print(f"Category: {classification['category']}")
    print(f"Severity: {classification['severity']}")
    print(f"Confidence: {classification['confidence']}")
    print(f"Reasoning: {classification['reasoning']}")

    assert classification['category'] == 'infrastructure'
    assert classification['severity'] == 'critical'

if __name__ == '__main__':
    test_classify_db_failure()
```

---

## Phase 4: ì¸í”„ë¼ ë¶„ì„ ì—ì´ì „íŠ¸ êµ¬í˜„ (2-3ì‹œê°„)

### ëª©í‘œ
ì¸í”„ë¼ ê´€ë ¨ ì´ìŠˆë¥¼ ìƒì„¸ ë¶„ì„

### íŒŒì¼: `src/agents/infrastructure_analyst.py`

### êµ¬í˜„ ë‚´ìš©

#### 4-1. ë¶„ì„ í”„ë¡¬í”„íŠ¸

```python
INFRASTRUCTURE_ANALYSIS_PROMPT = """ë‹¹ì‹ ì€ ì¸í”„ë¼ ë¬¸ì œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

=== ë¡œê·¸ ë°ì´í„° ===
{logs}

=== ë¶„ì„ ìš”ì²­ ===
ë‹¤ìŒ í•­ëª©ì„ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:

{{
  "issue_type": "ë¬¸ì œ ìœ í˜• (ì˜ˆ: Database Connection Failure)",
  "severity": "critical | high | medium | low",
  "first_occurrence": "ìµœì´ˆ ë°œìƒ ì‹œê°„",
  "affected_components": ["ì˜í–¥ë°›ì€ ì»´í¬ë„ŒíŠ¸ ëª©ë¡"],
  "error_count": ì—ëŸ¬ ë°œìƒ íšŸìˆ˜,
  "pattern": "ë°œê²¬ëœ íŒ¨í„´ ì„¤ëª…",
  "root_cause": "ì˜ˆìƒë˜ëŠ” ê·¼ë³¸ ì›ì¸",
  "impact": {{
    "service_availability": "ì„œë¹„ìŠ¤ ê°€ìš©ì„± (%)",
    "affected_users": "ì˜í–¥ë°›ì€ ì‚¬ìš©ì ë²”ìœ„",
    "data_loss_risk": "ë°ì´í„° ì†ì‹¤ ìœ„í—˜ (high/medium/low/none)"
  }},
  "recommendations": [
    "ê¶Œì¥ ì¡°ì¹˜ 1",
    "ê¶Œì¥ ì¡°ì¹˜ 2",
    "ê¶Œì¥ ì¡°ì¹˜ 3"
  ]
}}
"""
```

#### 4-2. ë¶„ì„ ì—ì´ì „íŠ¸ í´ë˜ìŠ¤

```python
class InfrastructureAnalyst:
    def __init__(self):
        self.llm = ChatOpenAI(model="gpt-4", temperature=0.0)
        self.prompt = ChatPromptTemplate.from_template(INFRASTRUCTURE_ANALYSIS_PROMPT)

    def analyze(self, parsed_logs: list) -> dict:
        """ì¸í”„ë¼ ì´ìŠˆ ë¶„ì„"""
        # ë¡œê·¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        logs_text = "\n".join([
            f"{log['timestamp']} [{log['level']}] {log['message']}"
            for log in parsed_logs
        ])

        # LLM í˜¸ì¶œ
        messages = self.prompt.format_messages(logs=logs_text)
        response = self.llm.invoke(messages)

        # JSON íŒŒì‹±
        try:
            return json.loads(response.content)
        except json.JSONDecodeError:
            return {"error": "ë¶„ì„ ì‹¤íŒ¨"}
```

### í…ŒìŠ¤íŠ¸

```python
# tests/test_infrastructure_analyst.py
from src.utils.log_parser import parse_log_file
from src.agents.infrastructure_analyst import InfrastructureAnalyst

def test_analyze_db_failure():
    # ë¡œê·¸ íŒŒì‹±
    result = parse_log_file('datasets/scenario-01-db-connection-failure/dataset-01.log')

    # ë¶„ì„
    analyst = InfrastructureAnalyst()
    analysis = analyst.analyze(result['logs'])

    print(json.dumps(analysis, indent=2, ensure_ascii=False))

    assert 'issue_type' in analysis
    assert 'recommendations' in analysis

if __name__ == '__main__':
    test_analyze_db_failure()
```

---

## Phase 5: LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„± (2-3ì‹œê°„)

### ëª©í‘œ
ì—ì´ì „íŠ¸ë“¤ì„ ì—°ê²°í•˜ì—¬ ìë™í™”ëœ ë¶„ì„ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•

### íŒŒì¼: `src/graph/workflow.py`

### êµ¬í˜„ ë‚´ìš©

#### 5-1. State ì •ì˜

```python
from typing import TypedDict, List, Dict

class AnalysisState(TypedDict):
    # ì…ë ¥
    log_file_path: str

    # íŒŒì‹± ê²°ê³¼
    parsed_logs: List[Dict]
    statistics: Dict

    # ë¶„ë¥˜ ê²°ê³¼
    classification: Dict

    # ë¶„ì„ ê²°ê³¼
    analysis: Dict

    # ìµœì¢… ë³´ê³ ì„œ
    report: str
```

#### 5-2. ë…¸ë“œ í•¨ìˆ˜ ì •ì˜

```python
from langgraph.graph import StateGraph, END
from src.utils.log_parser import parse_log_file
from src.agents.classifier import ClassificationAgent
from src.agents.infrastructure_analyst import InfrastructureAnalyst

def parse_logs_node(state: AnalysisState) -> AnalysisState:
    """ë¡œê·¸ íŒŒì‹± ë…¸ë“œ"""
    result = parse_log_file(state['log_file_path'])
    return {
        "parsed_logs": result['logs'],
        "statistics": result['statistics']
    }

def classify_node(state: AnalysisState) -> AnalysisState:
    """ë¶„ë¥˜ ë…¸ë“œ"""
    classifier = ClassificationAgent()
    classification = classifier.classify(
        state['parsed_logs'],
        state['statistics']
    )
    return {"classification": classification}

def analyze_infrastructure_node(state: AnalysisState) -> AnalysisState:
    """ì¸í”„ë¼ ë¶„ì„ ë…¸ë“œ"""
    analyst = InfrastructureAnalyst()
    analysis = analyst.analyze(state['parsed_logs'])
    return {"analysis": analysis}

def generate_report_node(state: AnalysisState) -> AnalysisState:
    """ë³´ê³ ì„œ ìƒì„± ë…¸ë“œ"""
    report = f"""
# ë¡œê·¸ ë¶„ì„ ë³´ê³ ì„œ

## ìš”ì•½
- **ë¬¸ì œ ìœ í˜•**: {state['classification']['category']}
- **ì‹¬ê°ë„**: {state['classification']['severity']}
- **ì´ ë¡œê·¸ ìˆ˜**: {state['statistics']['total']}
- **ì—ëŸ¬ ìˆ˜**: {state['statistics']['errors']}

## ìƒì„¸ ë¶„ì„
{state['analysis'].get('issue_type', 'N/A')}

## ê¶Œì¥ ì¡°ì¹˜
{chr(10).join(f"{i+1}. {r}" for i, r in enumerate(state['analysis'].get('recommendations', [])))}
"""
    return {"report": report}
```

#### 5-3. ê·¸ë˜í”„ êµ¬ì„±

```python
def create_analysis_workflow():
    """ë¶„ì„ ì›Œí¬í”Œë¡œìš° ìƒì„±"""
    workflow = StateGraph(AnalysisState)

    # ë…¸ë“œ ì¶”ê°€
    workflow.add_node("parse", parse_logs_node)
    workflow.add_node("classify", classify_node)
    workflow.add_node("analyze", analyze_infrastructure_node)
    workflow.add_node("report", generate_report_node)

    # ì—£ì§€ ì—°ê²°
    workflow.set_entry_point("parse")
    workflow.add_edge("parse", "classify")
    workflow.add_edge("classify", "analyze")
    workflow.add_edge("analyze", "report")
    workflow.add_edge("report", END)

    # ì»´íŒŒì¼
    app = workflow.compile()
    return app
```

### í…ŒìŠ¤íŠ¸

```python
# tests/test_workflow.py
from src.graph.workflow import create_analysis_workflow

def test_full_workflow():
    app = create_analysis_workflow()

    result = app.invoke({
        "log_file_path": "datasets/scenario-01-db-connection-failure/dataset-01.log"
    })

    print(result['report'])
    assert 'report' in result

if __name__ == '__main__':
    test_full_workflow()
```

---

## Phase 6: Chainlit UI êµ¬í˜„ (1-2ì‹œê°„)

### ëª©í‘œ
ì›¹ ê¸°ë°˜ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤

### íŒŒì¼: `src/ui/app.py`

### êµ¬í˜„ ë‚´ìš©

```python
import chainlit as cl
from src.graph.workflow import create_analysis_workflow

# ì›Œí¬í”Œë¡œìš° ìƒì„±
app = create_analysis_workflow()

@cl.on_chat_start
async def start():
    """ì±„íŒ… ì‹œì‘"""
    await cl.Message(
        content="""# ğŸ” ë¡œê·¸ ë¶„ì„ ì‹œìŠ¤í…œ

ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ AI ì—ì´ì „íŠ¸ê°€ ë¶„ì„í•©ë‹ˆë‹¤.

**ì§€ì› ì‹œë‚˜ë¦¬ì˜¤**:
- ğŸ”´ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¥ì• 
- ğŸŸ  ë³´ì•ˆ ê³µê²© (XSS, Brute Force)
- ğŸŸ¡ ì„±ëŠ¥ ë¬¸ì œ (N+1 ì¿¼ë¦¬, ë©”ëª¨ë¦¬ ëˆ„ìˆ˜)

íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!"""
    ).send()

@cl.on_message
async def main(message: cl.Message):
    """ë©”ì‹œì§€ ì²˜ë¦¬"""
    # íŒŒì¼ í™•ì¸
    if not message.elements:
        await cl.Message(content="âŒ ë¡œê·¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”!").send()
        return

    log_file = message.elements[0]

    # ì§„í–‰ ìƒí™© ë©”ì‹œì§€
    msg = cl.Message(content="")
    await msg.send()

    # ë¶„ì„ ì‹¤í–‰
    await msg.stream_token("## ğŸ”„ ë¶„ì„ ì¤‘...\n\n")
    await msg.stream_token("âœ… 1/4 ë¡œê·¸ íŒŒì‹± ì™„ë£Œ\n")

    result = app.invoke({"log_file_path": log_file.path})

    await msg.stream_token("âœ… 2/4 ë¬¸ì œ ë¶„ë¥˜ ì™„ë£Œ\n")
    await msg.stream_token("âœ… 3/4 ìƒì„¸ ë¶„ì„ ì™„ë£Œ\n")
    await msg.stream_token("âœ… 4/4 ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ\n\n")
    await msg.update()

    # ë³´ê³ ì„œ í‘œì‹œ
    await cl.Message(content=result['report']).send()
```

### ì‹¤í–‰

```bash
chainlit run src/ui/app.py
```

---

## Phase 7: ì¶”ê°€ ì—ì´ì „íŠ¸ í™•ì¥ (ì„ íƒì‚¬í•­)

### 7-1. ë³´ì•ˆ ë¶„ì„ ì—ì´ì „íŠ¸

**íŒŒì¼**: `src/agents/security_analyst.py`

**íƒì§€ í•­ëª©**:
- XSS ê³µê²© íŒ¨í„´
- ë¬´ì°¨ë³„ ëŒ€ì… ê³µê²©
- ê¶Œí•œ ìƒìŠ¹ ì‹œë„

### 7-2. ì„±ëŠ¥ ë¶„ì„ ì—ì´ì „íŠ¸

**íŒŒì¼**: `src/agents/performance_analyst.py`

**íƒì§€ í•­ëª©**:
- ëŠë¦° ì¿¼ë¦¬
- N+1 ë¬¸ì œ
- ë©”ëª¨ë¦¬ ëˆ„ìˆ˜

---

## ì²´í¬ë¦¬ìŠ¤íŠ¸

### í•„ìˆ˜ êµ¬í˜„ (MVP)
- [ ] í™˜ê²½ ì„¤ì • ì™„ë£Œ
- [ ] ë¡œê·¸ íŒŒì„œ êµ¬í˜„
- [ ] ë¶„ë¥˜ ì—ì´ì „íŠ¸ êµ¬í˜„
- [ ] ì¸í”„ë¼ ë¶„ì„ ì—ì´ì „íŠ¸ êµ¬í˜„
- [ ] LangGraph ì›Œí¬í”Œë¡œìš° êµ¬ì„±
- [ ] Chainlit UI êµ¬í˜„
- [ ] ì‹œë‚˜ë¦¬ì˜¤ 1 í…ŒìŠ¤íŠ¸ ì„±ê³µ

### ì„ íƒ êµ¬í˜„
- [ ] ë³´ì•ˆ ë¶„ì„ ì—ì´ì „íŠ¸
- [ ] ì„±ëŠ¥ ë¶„ì„ ì—ì´ì „íŠ¸
- [ ] ì¡°ê±´ë¶€ ë¼ìš°íŒ… êµ¬í˜„
- [ ] ë³´ê³ ì„œ PDF ë‹¤ìš´ë¡œë“œ
- [ ] ë‹¤ì¤‘ íŒŒì¼ ì—…ë¡œë“œ

---

## ë””ë²„ê¹… íŒ

### LLM ì‘ë‹µì´ JSONì´ ì•„ë‹ ë•Œ
```python
# response_format ì‚¬ìš©
llm = ChatOpenAI(model="gpt-4", temperature=0.0)
response = llm.invoke(messages, response_format={"type": "json_object"})
```

### í† í° ì œí•œ ì´ˆê³¼
```python
# ë¡œê·¸ ìƒ˜í”Œë§
sampled_logs = parsed_logs[::10]  # 10ê°œ ì¤‘ 1ê°œë§Œ
```

### ì—ëŸ¬ ì¶”ì 
```python
import logging
logging.basicConfig(level=logging.DEBUG)
```

---

## ë‹¤ìŒ ë‹¨ê³„

1. âœ… í™˜ê²½ ì„¤ì •ë¶€í„° ì‹œì‘
2. ê° Phaseë¥¼ ìˆœì„œëŒ€ë¡œ ì§„í–‰
3. ê° ë‹¨ê³„ë§ˆë‹¤ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
4. ë¬¸ì œ ë°œìƒ ì‹œ ë””ë²„ê¹… íŒ ì°¸ê³ 

í™”ì´íŒ…! ğŸš€